# -*- coding: utf-8 -*-
"""class_Dense_NN._6ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1b9BNTkXPaGTcTHDkjvvJDIqGxcz-4Pc6
"""

import tensorflow as tf

w = tf.Variable(tf.random.normal((3,2)))
b = tf.Variable([tf.zeros(2)])
x = tf.Variable([tf.random.normal((3,))])

with tf.GradientTape(watch_accessed_variables= False) as tape:
  tape.watch([w,b])
  y = x @ w - b
  loss = y**2

gd = tape.gradient(loss,[w,b])
gd[0],gd[1]



with tf.GradientTape(persistent= True) as tape:
  y = x*2
  f = y*y

df = tape.gradient(y,x)
k = tape.gradient(f,y)

p = tf.Variable(12.0)
with tf.GradientTape(watch_accessed_variables= False) as tape:
    tape.watch(x)
    y = 2 * x
    z = p*2
    f = y * y * z

df = tape.gradient(f,p)
print(df)

x = tf.Variable([1,2],dtype = tf.float32)

with tf.GradientTape() as tape:
  if tf.norm(x) < 25.0:
    y = x**2 * tf.Variable([1.0,5.0])
  else:
    y = tf.exp(x)

dfv = tape.gradient(y,x)
dfv

x = tf.Variable(1.0)
w = tf.Variable(2.0)

w.assign_add(x)

##5##

#gd
import matplotlib.pyplot as plt

points = 1000

x = tf.random.uniform(shape = [points], minval = 0,maxval = 10)
noise = tf.random.normal(shape = [points],stddev = 0.2)

k_true = 0.7
b_true = 0.2

y = k_true*x + b_true + noise

plt.scatter(x,y,s=2)

plt.show()

iter = 700
l_r = 0.02

k = tf.Variable(0.0)
b = tf.Variable(0.0)

for i in range(iter):
  with tf.GradientTape() as tape:
    f = k*x +b
    loss = tf.reduce_mean(tf.square((y-f)))

  dk,db = tape.gradient(loss,[k,b])
  b.assign_sub(l_r*db)
  k.assign_sub(l_r*dk)

y_pred = k*x + b

print(b,k,sep = '\n')

print(loss)

plt.scatter(x,y,s=2)
plt.scatter(x,y_pred,c ='r',s=2)
plt.show

# SGD
x_t = tf.random.uniform(shape = [1000],minval = 0,maxval = 10)
noise = tf.random.normal(shape = [1000],stddev = 0.2)

l_r = 0.02
k_t = 0.7
b_t = 0.2

y_t = k*x_t + b_t + noise

k_p = tf.Variable(0.0)
b_p = tf.Variable(0.0)

epochs = 50
batch_size = tf.Variable(100)
total_points = len(x_t)

#opt = tf.optimizers.SGD(learning_rate = 0.02,momentum = 0.3)
opt = tf.optimizers.Adam(0.1)

for i in range(epochs):
  for number_butch in range(total_points // batch_size):
    x_batch = x_t[number_butch*batch_size:number_butch*batch_size+ 100]
    y_batch = y_t[number_butch*batch_size:(number_butch+1)*batch_size]

    with tf.GradientTape() as tape:
      loss = tf.reduce_mean(tf.square((y_batch - k_p*x_batch - b_p)))

    dk,db = tape.gradient(loss,[k_p,b_p])
    opt.apply_gradients(zip([dk,db],[k_p,b_p]))
    #k_p.assign_sub(l_r*dk)
    #b_p.assign_sub(l_r*db)

print(k_p.numpy(),b_p.numpy())
y_pred = k_p*x_t + b_p

plt.scatter(x_t,y_t,s=2)
plt.scatter(x_t,y_pred,c= 'r',s=2)
plt.show

x = tf.random.normal((100,2))
b = tf.Variable(1.0)
w = tf.random.normal((5,2))

#x @ tf.transpose(w,perm = (1,0)) + b



import tensorflow as tf
import matplotlib.pyplot as plt

class DenseNN(tf.Module):
  def __init__(self,outputs):
    super().__init__()
    self.out = outputs
    self.fl_init = False

  def __call__(self,x):
    if not self.fl_init:
      self.w = tf.random.normal(shape = (x.shape[-1],self.out),stddev =0.2)
      self.b = tf.zeros(1,1)

      self.w = tf.Variable(self.w)
      self.b = tf.Variable(self.b)

      self.fl_init = True
    y = x @ self.w + self.b
    return y

model = DenseNN(1)

x_train = tf.random.uniform((100,2),minval = 0, maxval =10)
y_train  = [a +b for a,b in x_train ]

loss = lambda x,y: tf.reduce_mean(tf.square(y- x))
opt = tf.optimizers.Adam(0.02)

epochs = 50
for i in range(epochs):
  for x,y in zip(x_train,y_train):
    x = tf.expand_dims(x, axis=0)
    y = tf.constant(y,shape = (1,1))

    with tf.GradientTape() as tape:
      f_loss = loss(model(x),y)

    grads = tape.gradient(f_loss,model.trainable_variables)
    opt.apply_gradients(zip(grads, model.trainable_variables))

y_train = tf.Variable(y_train)
y_train = tf.expand_dims(y_train,axis = 1)

add_shape=  tf.zeros((100,1))

new_y = tf.concat([y_train,add_shape],axis =1 )



b = model.trainable_variables[0]
w1,w2 = model.trainable_variables[1]
w = tf.Variable((w1,w2))


y_pred = x_train @ w + b
y_pred = tf.concat([y_pred,add_shape],axis =1)

plt.scatter(x_train,new_y,s =2)
plt.scatter(x_train,y_pred,c= 'r',s=2)
plt.show

